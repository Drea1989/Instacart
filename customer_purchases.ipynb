{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#import the needed libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #Supress unnecessary warnings for readability and cleaner presentation\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "color = sns.color_palette()\n",
    "\n",
    "import pickle\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) #Limiting floats output to 3 decimal points\n",
    "import gc\n",
    "print (gc.isenabled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#deeplearning\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Model,Sequential\n",
    "\n",
    "from keras.layers.core import Dense, Reshape, Lambda,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, Embedding, merge\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate all product-ids into a single string\n",
    "# thanks to https://www.kaggle.com/eoakley/start-here-simple-submission\n",
    "\n",
    "def products_concat(series):\n",
    "    out = ''\n",
    "    for product in series:\n",
    "           out = out + str(int(product)) + ' '\n",
    "    \n",
    "    if out != '':\n",
    "        return out.rstrip()\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_split(df):\n",
    "    df_reordered = df[df['reordered'] == 1]\n",
    "    df_reordered = df_reordered.groupby('order_id')['product_id'].apply(products_concat)\n",
    "    \n",
    "    try:\n",
    "        df_reordered = df_reordered.reset_index()\n",
    "        df_reordered.columns = ['order_id','products_list']\n",
    "    except:\n",
    "        df_reordered = df_reordered.reset_index(level = ['order_id'])\n",
    "        df_reordered.columns = ['order_id','products_list']\n",
    "        \n",
    "    return df_reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "def multilabel_fscore(ytrue, ypred):\n",
    "    \"\"\"\n",
    "    ex1:\n",
    "    y_true = [1, 2, 3]\n",
    "    y_pred = [2, 3]\n",
    "    return: 0.8\n",
    "    \n",
    "    ex2:\n",
    "    y_true = [\"None\"]\n",
    "    y_pred = [2, \"None\"]\n",
    "    return: 0.666\n",
    "    \n",
    "    ex3:\n",
    "    y_true = [4, 5, 6, 7]\n",
    "    y_pred = [2, 4, 8, 9]\n",
    "    return: 0.25\n",
    "    \n",
    "    \"\"\"\n",
    "    #y_true = K.eval(ytrue)\n",
    "    #y_pred = K.eval(ypred)\n",
    "    F1_score = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for items in range(len(ytrue)):\n",
    "        y_true = ytrue[items]\n",
    "        y_pred = ypred[items]\n",
    "        correct = sum([1 for i in y_pred if i in y_true])\n",
    "        if correct > 0:\n",
    "\n",
    "            precision = correct / len(y_pred)\n",
    "\n",
    "            recall =    correct / len(y_true)\n",
    "\n",
    "            F1_score.append((2 * precision * recall) / (precision + recall))\n",
    "\n",
    "        else:\n",
    "            F1_score.append(0)\n",
    "\n",
    "    return np.mean(F1_score)\n",
    "\n",
    "#if __name__ != '__main__':\n",
    "\n",
    "print(multilabel_fscore([[2,3],['None']], [[2,3,4],['None']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's get and put the data in  pandas dataframe\n",
    "order_products_train = pd.read_csv('/training/order_products__train.csv')\n",
    "order_products_prior = pd.read_csv('/training/order_products__prior.csv')\n",
    "orders = pd.read_csv('/training/orders.csv',engine ='c')\n",
    "#aisles = pd.read_csv('input/aisles.csv')\n",
    "#departments = pd.read_csv('input/departments.csv')\n",
    "display(order_products_prior.head(1))\n",
    "display(orders.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('/training/products.csv')\n",
    "value = list(products['product_id'].astype(str))\n",
    "value.append('None')\n",
    "#save data\n",
    "pickle.dump(value, open('prod_dict.p', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create one hot encode of aisle and dept\n",
    "df_additional = products[['product_id','aisle_id','department_id']]\n",
    "df_additional[['aisle_id','department_id']] = df_additional[['aisle_id','department_id']].astype(str)\n",
    "df_additional = pd.get_dummies(df_additional, columns=['aisle_id','department_id'])\n",
    "display(df_additional.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_reo = order_products_prior[order_products_prior['reordered'] == 1].drop(['reordered','add_to_cart_order'], axis=1)\n",
    "display(prior_reo.head(1))\n",
    "train_reo = order_products_train[order_products_train['reordered'] == 1].drop(['reordered','add_to_cart_order'], axis=1)\n",
    "prior_reo = prior_reo.merge(train_reo,on=['order_id','product_id'], how = 'outer')\n",
    "display(prior_reo.head(1))\n",
    "prior_reo = prior_reo.merge(df_additional, on='product_id', how='left')\n",
    "print('joined')\n",
    "prior_reo = prior_reo.drop(['product_id'], axis =1)\n",
    "print('merging')\n",
    "prior_reo = prior_reo.merge(orders[['user_id','order_number','order_id']],on='order_id', how='left')\n",
    "prior_reo = prior_reo.sort_values(['user_id','order_number'])\n",
    "print (prior_reo.info())\n",
    "print('aggregating')\n",
    "prior_reo = prior_reo.groupby(['user_id','order_number', 'order_id']).sum()\n",
    "display(prior_reo.head(5))\n",
    "print('shifting previous orders')\n",
    "prior_reo= prior_reo.groupby(level=0).shift(1)\n",
    "#apply(lambda x: pd.rolling_sum(x, window=2, min_periods=0)\n",
    "prior_reo = prior_reo.reset_index()\n",
    "display(prior_reo.head(5))\n",
    "#print('saving')\n",
    "#prior_reo.to_csv('input/prior_prods.csv', index=False)\n",
    "#display(prior_reo.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_prod_list = order_products_train.merge(order_products_prior, how = 'outer')\n",
    "display(order_prod_list.head(1))\n",
    "df_prior_prod = df_split(order_prod_list)\n",
    "display(df_prior_prod.head(1))\n",
    "df_train = orders.merge(df_prior_prod, on='order_id', how='left')\n",
    "df_train = df_train.merge(prior_reo, on=['order_id','user_id','order_number'], how='left')\n",
    "df_train['products_list'] = df_train['products_list'].fillna('None')\n",
    "df_train = df_train.fillna(0)\n",
    "display(df_train.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = df_train[df_train['eval_set'] == 'train']\n",
    "display(df_eval.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del order_products_train,order_products_prior,orders,products,order_prod_list\n",
    "del df_prior_prod, prior_reo, df_additional\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = df_eval.drop(['eval_set','user_id'], axis =1)\n",
    "\n",
    "df_test =  df_train[df_train['eval_set'] == 'test']\n",
    "df_train = df_train[df_train['eval_set'] == 'prior']\n",
    "df_train = df_train.drop(['eval_set','user_id'], axis =1)\n",
    "display(df_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save data\n",
    "pickle.dump(df_eval, open('eval_orders.p', 'wb'), protocol=4)\n",
    "\n",
    "pickle.dump(df_train, open('train_orders.p', 'wb'), protocol=4)\n",
    "\n",
    "pickle.dump(df_test, open('test_orders.p', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "data can be loaded from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest = open('test_orders.p','rb')\\ntest_orders = pickle.load(test)\\ntest.close()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "evals = open('eval_orders.p','rb')\n",
    "df_eval = pickle.load(evals)\n",
    "evals.close()\n",
    "\n",
    "train = open('train_orders.p','rb')\n",
    "df_train = pickle.load(train)\n",
    "train.close()\n",
    "'''\n",
    "df_train = pd.read_pickle(open('train_orders.p','rb'))\n",
    "'''\n",
    "test = open('test_orders.p','rb')\n",
    "test_orders = pickle.load(test)\n",
    "test.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['products_list'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### setting up keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.set_index('order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_number</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>aisle_id_1</th>\n",
       "      <th>aisle_id_10</th>\n",
       "      <th>aisle_id_100</th>\n",
       "      <th>aisle_id_101</th>\n",
       "      <th>aisle_id_102</th>\n",
       "      <th>aisle_id_103</th>\n",
       "      <th>aisle_id_104</th>\n",
       "      <th>aisle_id_105</th>\n",
       "      <th>...</th>\n",
       "      <th>order_hour_of_day_21</th>\n",
       "      <th>order_hour_of_day_22</th>\n",
       "      <th>order_hour_of_day_23</th>\n",
       "      <th>order_hour_of_day_3</th>\n",
       "      <th>order_hour_of_day_4</th>\n",
       "      <th>order_hour_of_day_5</th>\n",
       "      <th>order_hour_of_day_6</th>\n",
       "      <th>order_hour_of_day_7</th>\n",
       "      <th>order_hour_of_day_8</th>\n",
       "      <th>order_hour_of_day_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2539329</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>2</td>\n",
       "      <td>15.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473747</th>\n",
       "      <td>3</td>\n",
       "      <td>21.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254736</th>\n",
       "      <td>4</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431534</th>\n",
       "      <td>5</td>\n",
       "      <td>28.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_number  days_since_prior_order  aisle_id_1  aisle_id_10  \\\n",
       "order_id                                                                  \n",
       "2539329              1                   0.000       0.000        0.000   \n",
       "2398795              2                  15.000       0.000        0.000   \n",
       "473747               3                  21.000       0.000        0.000   \n",
       "2254736              4                  29.000       0.000        0.000   \n",
       "431534               5                  28.000       0.000        0.000   \n",
       "\n",
       "          aisle_id_100  aisle_id_101  aisle_id_102  aisle_id_103  \\\n",
       "order_id                                                           \n",
       "2539329          0.000         0.000         0.000         0.000   \n",
       "2398795          0.000         0.000         0.000         0.000   \n",
       "473747           0.000         0.000         0.000         0.000   \n",
       "2254736          0.000         0.000         0.000         0.000   \n",
       "431534           0.000         0.000         0.000         0.000   \n",
       "\n",
       "          aisle_id_104  aisle_id_105         ...           \\\n",
       "order_id                                     ...            \n",
       "2539329          0.000         0.000         ...            \n",
       "2398795          0.000         0.000         ...            \n",
       "473747           0.000         0.000         ...            \n",
       "2254736          0.000         0.000         ...            \n",
       "431534           0.000         0.000         ...            \n",
       "\n",
       "          order_hour_of_day_21  order_hour_of_day_22  order_hour_of_day_23  \\\n",
       "order_id                                                                     \n",
       "2539329                      0                     0                     0   \n",
       "2398795                      0                     0                     0   \n",
       "473747                       0                     0                     0   \n",
       "2254736                      0                     0                     0   \n",
       "431534                       0                     0                     0   \n",
       "\n",
       "          order_hour_of_day_3  order_hour_of_day_4  order_hour_of_day_5  \\\n",
       "order_id                                                                  \n",
       "2539329                     0                    0                    0   \n",
       "2398795                     0                    0                    0   \n",
       "473747                      0                    0                    0   \n",
       "2254736                     0                    0                    0   \n",
       "431534                      0                    0                    0   \n",
       "\n",
       "          order_hour_of_day_6  order_hour_of_day_7  order_hour_of_day_8  \\\n",
       "order_id                                                                  \n",
       "2539329                     0                    0                    1   \n",
       "2398795                     0                    1                    0   \n",
       "473747                      0                    0                    0   \n",
       "2254736                     0                    1                    0   \n",
       "431534                      0                    0                    0   \n",
       "\n",
       "          order_hour_of_day_9  \n",
       "order_id                       \n",
       "2539329                     0  \n",
       "2398795                     0  \n",
       "473747                      0  \n",
       "2254736                     0  \n",
       "431534                      0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train[['order_dow', 'order_hour_of_day']] = X_train[['order_dow', 'order_hour_of_day']].astype(str)\n",
    "X_train = pd.get_dummies(X_train, columns=['order_dow', 'order_hour_of_day'])\n",
    "\n",
    "X_train = X_train.fillna(-1)\n",
    "X_train = X_train.replace(0,-1)\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('None',)\n",
      "196 12427 26088\n",
      "('None',)\n"
     ]
    }
   ],
   "source": [
    "#vectorise the products list\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "value = pickle.load( open('prod_dict.p', 'rb'))\n",
    "dicts = []\n",
    "for i in value:\n",
    "    dicts.append(tuple(i.split()))\n",
    "print (dicts[49688])\n",
    "\n",
    "\n",
    "vectorizer = MultiLabelBinarizer(sparse_output=True).fit(dicts)\n",
    "\n",
    "#prod_dict = {value:key  for (value, key) in zip(value, key)}\n",
    "#print (list(vectorizer.classes_))\n",
    "#print (key[49688])\n",
    "#print (value[49688])\n",
    "#vectorizer = TfidfVectorizer(vocabulary = prod_dict)\n",
    "#vectorizer = CountVectorizer(vocabulary = prod_dict)\n",
    "train_target = df_train['products_list'].values\n",
    "\n",
    "print(train_target[1])\n",
    "y_train = []\n",
    "for i in train_target:\n",
    "    y_train.append(tuple(i.split()))\n",
    "print (y_train[0])\n",
    "    \n",
    "\n",
    "y_train = vectorizer.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#custom round layer\n",
    "from keras.layers import Layer\n",
    "class Round(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Round, self).__init__(**kwargs)\n",
    "\n",
    "    def get_output(self, train=False):\n",
    "        X = self.get_input(train)\n",
    "        return K.round(X)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(Round, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "print (vectorizer.classes_[49688])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('33845', '2517', '47630', '39877')]\n"
     ]
    }
   ],
   "source": [
    "y = y_train[:70000].todense()\n",
    "\n",
    "y_eval = y[69900:]\n",
    "y = y[:69900]\n",
    "\n",
    "test = vectorizer.inverse_transform(y_train[1450])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3214874, 188)\n",
      "(100, 49689)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(212,input_dim=188, activation='relu'))\n",
    "# Hidden layers\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(316,activation='relu'))\n",
    "model.add(Dense(486,activation='relu'))\n",
    "model.add(Dense(624,activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(700,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(700,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "#output layer\n",
    "model.add(Dense(49689, activation='sigmoid'))\n",
    "\n",
    "#adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.99, epsilon=1e-03, decay=0.0001)\n",
    "RMSprop = keras.optimizers.RMSprop(lr=0.0001)\n",
    "#Nadam = keras.optimizers.Nadam(lr=0.001)\n",
    "#Adagrad = keras.optimizers.Adagrad(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy',optimizer= RMSprop, metrics = ['categorical_accuracy'])\n",
    "\n",
    "keras_train = np.array(X_train[:69900])\n",
    "keras_eval = np.array(X_train[69900:70000])\n",
    "\n",
    "print (y_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_number</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>aisle_id_1</th>\n",
       "      <th>aisle_id_10</th>\n",
       "      <th>aisle_id_100</th>\n",
       "      <th>aisle_id_101</th>\n",
       "      <th>aisle_id_102</th>\n",
       "      <th>aisle_id_103</th>\n",
       "      <th>aisle_id_104</th>\n",
       "      <th>aisle_id_105</th>\n",
       "      <th>...</th>\n",
       "      <th>order_hour_of_day_21</th>\n",
       "      <th>order_hour_of_day_22</th>\n",
       "      <th>order_hour_of_day_23</th>\n",
       "      <th>order_hour_of_day_3</th>\n",
       "      <th>order_hour_of_day_4</th>\n",
       "      <th>order_hour_of_day_5</th>\n",
       "      <th>order_hour_of_day_6</th>\n",
       "      <th>order_hour_of_day_7</th>\n",
       "      <th>order_hour_of_day_8</th>\n",
       "      <th>order_hour_of_day_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2539329</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_number  days_since_prior_order  aisle_id_1  aisle_id_10  \\\n",
       "order_id                                                                  \n",
       "2539329              1                   0.000       0.000        0.000   \n",
       "\n",
       "          aisle_id_100  aisle_id_101  aisle_id_102  aisle_id_103  \\\n",
       "order_id                                                           \n",
       "2539329          0.000         0.000         0.000         0.000   \n",
       "\n",
       "          aisle_id_104  aisle_id_105         ...           \\\n",
       "order_id                                     ...            \n",
       "2539329          0.000         0.000         ...            \n",
       "\n",
       "          order_hour_of_day_21  order_hour_of_day_22  order_hour_of_day_23  \\\n",
       "order_id                                                                     \n",
       "2539329                      0                     0                     0   \n",
       "\n",
       "          order_hour_of_day_3  order_hour_of_day_4  order_hour_of_day_5  \\\n",
       "order_id                                                                  \n",
       "2539329                     0                    0                    0   \n",
       "\n",
       "          order_hour_of_day_6  order_hour_of_day_7  order_hour_of_day_8  \\\n",
       "order_id                                                                  \n",
       "2539329                     0                    0                    1   \n",
       "\n",
       "          order_hour_of_day_9  \n",
       "order_id                       \n",
       "2539329                     0  \n",
       "\n",
       "[1 rows x 188 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 69201 samples, validate on 699 samples\n",
      "Epoch 1/10\n",
      "60s - loss: 0.0930 - categorical_accuracy: 0.0686 - val_loss: 0.0064 - val_categorical_accuracy: 0.1087\n",
      "Epoch 2/10\n",
      "59s - loss: 0.0010 - categorical_accuracy: 0.0944 - val_loss: 0.0021 - val_categorical_accuracy: 0.1073\n",
      "Epoch 3/10\n",
      "59s - loss: 8.7736e-04 - categorical_accuracy: 0.1111 - val_loss: 0.0015 - val_categorical_accuracy: 0.0887\n",
      "Epoch 4/10\n",
      "59s - loss: 8.6184e-04 - categorical_accuracy: 0.1248 - val_loss: 0.0012 - val_categorical_accuracy: 0.0887\n",
      "Epoch 5/10\n",
      "59s - loss: 8.5344e-04 - categorical_accuracy: 0.1303 - val_loss: 0.0012 - val_categorical_accuracy: 0.1087\n",
      "Epoch 6/10\n",
      "59s - loss: 8.4805e-04 - categorical_accuracy: 0.1337 - val_loss: 0.0012 - val_categorical_accuracy: 0.0801\n",
      "Epoch 7/10\n",
      "60s - loss: 8.4305e-04 - categorical_accuracy: 0.1370 - val_loss: 0.0011 - val_categorical_accuracy: 0.1116\n",
      "Epoch 8/10\n",
      "59s - loss: 8.3766e-04 - categorical_accuracy: 0.1396 - val_loss: 0.0011 - val_categorical_accuracy: 0.1202\n",
      "Epoch 9/10\n",
      "60s - loss: 8.3252e-04 - categorical_accuracy: 0.1420 - val_loss: 0.0011 - val_categorical_accuracy: 0.0987\n",
      "Epoch 10/10\n",
      "59s - loss: 8.2988e-04 - categorical_accuracy: 0.1433 - val_loss: 0.0011 - val_categorical_accuracy: 0.1159\n",
      " 96/100 [===========================>..] - ETA: 0s\n",
      "Test score: 0.000675324760377\n",
      "Test accuracy: 0.15\n"
     ]
    }
   ],
   "source": [
    "display(X_train.head(1))\n",
    "print('Training')\n",
    "# since we are using stateful rnn tsteps can be set to 1\n",
    "tsteps = 1\n",
    "batch_size = 25\n",
    "epochs = 25\n",
    "# Fit the model\n",
    "\n",
    "model.fit(keras_train, y, epochs=10, batch_size=1000,verbose=2, validation_split = 0.01) \n",
    "\n",
    "score = model.evaluate(keras_eval, y_eval)\n",
    "\n",
    "print('\\nTest score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#for i in range(epochs):\n",
    "#    print('Epoch', i, '/', epochs)\n",
    "\n",
    "    # Note that the last state for sample i in a batch will\n",
    "    # be used as initial state for sample i in the next batch.\n",
    "    # Thus we are simultaneously training on batch_size series with\n",
    "    # lower resolution than the original series contained in cos.\n",
    "    # Each of these series are offset by one step and can be\n",
    "    # extracted with cos[i::batch_size].\n",
    "#    model.fit(X_train, train_target,\n",
    "#              batch_size=batch_size,\n",
    "#              epochs=1,\n",
    "#              verbose=1)\n",
    "#    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "true eval set values ('33845', '2517', '47630', '39877')\n",
      "pred eval set values ()\n",
      "\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print('Predicting')\n",
    "predicted_output = model.predict(keras_eval)\n",
    "\n",
    "predicted_output[predicted_output>=0.5] = 1\n",
    "predicted_output[predicted_output<0.5] = 0\n",
    "\n",
    "y_eval_pred = vectorizer.inverse_transform(predicted_output)\n",
    "\n",
    "print('true eval set values {}'.format(test[0]))\n",
    "print('pred eval set values {}\\n'.format(y_eval_pred[0]))\n",
    "\n",
    "print (multilabel_fscore(test,y_eval_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

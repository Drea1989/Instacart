{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#import the needed libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #Supress unnecessary warnings for readability and cleaner presentation\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "color = sns.color_palette()\n",
    "\n",
    "import pickle\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) #Limiting floats output to 3 decimal points\n",
    "import gc\n",
    "print (gc.isenabled())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#deeplearning\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Model,Sequential\n",
    "\n",
    "from keras.layers.core import Dense, Reshape, Lambda,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input, Embedding, merge\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate all product-ids into a single string\n",
    "# thanks to https://www.kaggle.com/eoakley/start-here-simple-submission\n",
    "\n",
    "def products_concat(series):\n",
    "    out = ''\n",
    "    for product in series:\n",
    "           out = out + str(int(product)) + ' '\n",
    "    \n",
    "    if out != '':\n",
    "        return out.rstrip()\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_split(df):\n",
    "    df_reordered = df[df['reordered'] == 1]\n",
    "    df_reordered = df_reordered.groupby('order_id')['product_id'].apply(products_concat)\n",
    "    \n",
    "    try:\n",
    "        df_reordered = df_reordered.reset_index()\n",
    "        df_reordered.columns = ['order_id','products_list']\n",
    "    except:\n",
    "        df_reordered = df_reordered.reset_index(level = ['order_id'])\n",
    "        df_reordered.columns = ['order_id','products_list']\n",
    "        \n",
    "    return df_reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "def multilabel_fscore(ytrue, ypred):\n",
    "    \"\"\"\n",
    "    ex1:\n",
    "    y_true = [1, 2, 3]\n",
    "    y_pred = [2, 3]\n",
    "    return: 0.8\n",
    "    \n",
    "    ex2:\n",
    "    y_true = [\"None\"]\n",
    "    y_pred = [2, \"None\"]\n",
    "    return: 0.666\n",
    "    \n",
    "    ex3:\n",
    "    y_true = [4, 5, 6, 7]\n",
    "    y_pred = [2, 4, 8, 9]\n",
    "    return: 0.25\n",
    "    \n",
    "    \"\"\"\n",
    "    #y_true = K.eval(ytrue)\n",
    "    #y_pred = K.eval(ypred)\n",
    "    F1_score = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for items in range(len(ytrue)):\n",
    "        y_true = ytrue[items]\n",
    "        y_pred = ypred[items]\n",
    "        correct = sum([1 for i in y_pred if i in y_true])\n",
    "        if correct > 0:\n",
    "\n",
    "            precision = correct / len(y_pred)\n",
    "\n",
    "            recall =    correct / len(y_true)\n",
    "\n",
    "            F1_score.append((2 * precision * recall) / (precision + recall))\n",
    "\n",
    "        else:\n",
    "            F1_score.append(0)\n",
    "\n",
    "    return np.mean(F1_score)\n",
    "\n",
    "#if __name__ != '__main__':\n",
    "\n",
    "print(multilabel_fscore([[2,3],['None']], [[2,3,4],['None']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's get and put the data in  pandas dataframe\n",
    "order_products_train = pd.read_csv('/training/order_products__train.csv')\n",
    "order_products_prior = pd.read_csv('/training/order_products__prior.csv')\n",
    "orders = pd.read_csv('/training/orders.csv',engine ='c')\n",
    "#aisles = pd.read_csv('input/aisles.csv')\n",
    "#departments = pd.read_csv('input/departments.csv')\n",
    "display(order_products_prior.head(1))\n",
    "display(orders.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('/training/products.csv')\n",
    "value = list(products['product_id'].astype(str))\n",
    "value.append('None')\n",
    "#save data\n",
    "pickle.dump(value, open('prod_dict.p', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create one hot encode of aisle and dept\n",
    "df_additional = products[['product_id','aisle_id','department_id']]\n",
    "df_additional[['aisle_id','department_id']] = df_additional[['aisle_id','department_id']].astype(str)\n",
    "df_additional = pd.get_dummies(df_additional, columns=['aisle_id','department_id'])\n",
    "display(df_additional.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_reo = order_products_prior[order_products_prior['reordered'] == 1].drop(['reordered','add_to_cart_order'], axis=1)\n",
    "display(prior_reo.head(1))\n",
    "train_reo = order_products_train[order_products_train['reordered'] == 1].drop(['reordered','add_to_cart_order'], axis=1)\n",
    "prior_reo = prior_reo.merge(train_reo,on=['order_id','product_id'], how = 'outer')\n",
    "display(prior_reo.head(1))\n",
    "prior_reo = prior_reo.merge(df_additional, on='product_id', how='left')\n",
    "print('joined')\n",
    "prior_reo = prior_reo.drop(['product_id'], axis =1)\n",
    "print('merging')\n",
    "prior_reo = prior_reo.merge(orders[['user_id','order_number','order_id']],on='order_id', how='left')\n",
    "prior_reo = prior_reo.sort_values(['user_id','order_number'])\n",
    "print (prior_reo.info())\n",
    "print('aggregating')\n",
    "prior_reo = prior_reo.groupby(['user_id','order_number', 'order_id']).sum()\n",
    "display(prior_reo.head(5))\n",
    "print('shifting previous orders')\n",
    "prior_reo= prior_reo.groupby(level=0).shift(1)\n",
    "#apply(lambda x: pd.rolling_sum(x, window=2, min_periods=0)\n",
    "prior_reo = prior_reo.reset_index()\n",
    "display(prior_reo.head(5))\n",
    "#print('saving')\n",
    "#prior_reo.to_csv('input/prior_prods.csv', index=False)\n",
    "#display(prior_reo.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_prod_list = order_products_train.merge(order_products_prior, how = 'outer')\n",
    "display(order_prod_list.head(1))\n",
    "df_prior_prod = df_split(order_prod_list)\n",
    "display(df_prior_prod.head(1))\n",
    "df_train = orders.merge(df_prior_prod, on='order_id', how='left')\n",
    "df_train = df_train.merge(prior_reo, on=['order_id','user_id','order_number'], how='left')\n",
    "df_train['products_list'] = df_train['products_list'].fillna('None')\n",
    "df_train = df_train.fillna(0)\n",
    "display(df_train.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_eval = df_train[df_train['eval_set'] == 'train']\n",
    "display(df_eval.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del order_products_train,order_products_prior,orders,products,order_prod_list\n",
    "del df_prior_prod, prior_reo, df_additional\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_eval = df_eval.drop(['eval_set','user_id'], axis =1)\n",
    "\n",
    "df_test =  df_train[df_train['eval_set'] == 'test']\n",
    "df_train = df_train[df_train['eval_set'] == 'prior']\n",
    "df_train = df_train.drop(['eval_set','user_id'], axis =1)\n",
    "display(df_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save data\n",
    "pickle.dump(df_eval, open('eval_orders.p', 'wb'), protocol=4)\n",
    "\n",
    "pickle.dump(df_train, open('train_orders.p', 'wb'), protocol=4)\n",
    "\n",
    "pickle.dump(df_test, open('test_orders.p', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "data can be loaded from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntest = open('test_orders.p','rb')\\ntest_orders = pickle.load(test)\\ntest.close()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "evals = open('eval_orders.p','rb')\n",
    "df_eval = pickle.load(evals)\n",
    "evals.close()\n",
    "\n",
    "train = open('train_orders.p','rb')\n",
    "df_train = pickle.load(train)\n",
    "train.close()\n",
    "'''\n",
    "df_train = pd.read_pickle(open('/training/train_orders.p','rb'))\n",
    "'''\n",
    "test = open('test_orders.p','rb')\n",
    "test_orders = pickle.load(test)\n",
    "test.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['products_list'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### setting up keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>aisle_id_1</th>\n",
       "      <th>aisle_id_10</th>\n",
       "      <th>aisle_id_100</th>\n",
       "      <th>aisle_id_101</th>\n",
       "      <th>aisle_id_102</th>\n",
       "      <th>aisle_id_103</th>\n",
       "      <th>...</th>\n",
       "      <th>department_id_2</th>\n",
       "      <th>department_id_20</th>\n",
       "      <th>department_id_21</th>\n",
       "      <th>department_id_3</th>\n",
       "      <th>department_id_4</th>\n",
       "      <th>department_id_5</th>\n",
       "      <th>department_id_6</th>\n",
       "      <th>department_id_7</th>\n",
       "      <th>department_id_8</th>\n",
       "      <th>department_id_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2539329</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_number  order_dow  order_hour_of_day  days_since_prior_order  \\\n",
       "order_id                                                                       \n",
       "2539329              1          2                  8                   0.000   \n",
       "\n",
       "          aisle_id_1  aisle_id_10  aisle_id_100  aisle_id_101  aisle_id_102  \\\n",
       "order_id                                                                      \n",
       "2539329        0.000        0.000         0.000         0.000         0.000   \n",
       "\n",
       "          aisle_id_103       ...         department_id_2  department_id_20  \\\n",
       "order_id                     ...                                             \n",
       "2539329          0.000       ...                   0.000             0.000   \n",
       "\n",
       "          department_id_21  department_id_3  department_id_4  department_id_5  \\\n",
       "order_id                                                                        \n",
       "2539329              0.000            0.000            0.000            0.000   \n",
       "\n",
       "          department_id_6  department_id_7  department_id_8  department_id_9  \n",
       "order_id                                                                      \n",
       "2539329             0.000            0.000            0.000            0.000  \n",
       "\n",
       "[1 rows x 159 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X_train.set_index('order_id')\n",
    "display(X_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_number</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>aisle_id_1</th>\n",
       "      <th>aisle_id_10</th>\n",
       "      <th>aisle_id_100</th>\n",
       "      <th>aisle_id_101</th>\n",
       "      <th>aisle_id_102</th>\n",
       "      <th>aisle_id_103</th>\n",
       "      <th>aisle_id_104</th>\n",
       "      <th>aisle_id_105</th>\n",
       "      <th>...</th>\n",
       "      <th>order_hour_of_day_21</th>\n",
       "      <th>order_hour_of_day_22</th>\n",
       "      <th>order_hour_of_day_23</th>\n",
       "      <th>order_hour_of_day_3</th>\n",
       "      <th>order_hour_of_day_4</th>\n",
       "      <th>order_hour_of_day_5</th>\n",
       "      <th>order_hour_of_day_6</th>\n",
       "      <th>order_hour_of_day_7</th>\n",
       "      <th>order_hour_of_day_8</th>\n",
       "      <th>order_hour_of_day_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2539329</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_number  days_since_prior_order  aisle_id_1  aisle_id_10  \\\n",
       "order_id                                                                  \n",
       "2539329              1                       0           0            0   \n",
       "\n",
       "          aisle_id_100  aisle_id_101  aisle_id_102  aisle_id_103  \\\n",
       "order_id                                                           \n",
       "2539329              0             0             0             0   \n",
       "\n",
       "          aisle_id_104  aisle_id_105         ...           \\\n",
       "order_id                                     ...            \n",
       "2539329              0             0         ...            \n",
       "\n",
       "          order_hour_of_day_21  order_hour_of_day_22  order_hour_of_day_23  \\\n",
       "order_id                                                                     \n",
       "2539329                      0                     0                     0   \n",
       "\n",
       "          order_hour_of_day_3  order_hour_of_day_4  order_hour_of_day_5  \\\n",
       "order_id                                                                  \n",
       "2539329                     0                    0                    0   \n",
       "\n",
       "          order_hour_of_day_6  order_hour_of_day_7  order_hour_of_day_8  \\\n",
       "order_id                                                                  \n",
       "2539329                     0                    0                    1   \n",
       "\n",
       "          order_hour_of_day_9  \n",
       "order_id                       \n",
       "2539329                     0  \n",
       "\n",
       "[1 rows x 188 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_number</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>aisle_id_1</th>\n",
       "      <th>aisle_id_10</th>\n",
       "      <th>aisle_id_100</th>\n",
       "      <th>aisle_id_101</th>\n",
       "      <th>aisle_id_102</th>\n",
       "      <th>aisle_id_103</th>\n",
       "      <th>aisle_id_104</th>\n",
       "      <th>aisle_id_105</th>\n",
       "      <th>...</th>\n",
       "      <th>order_hour_of_day_21</th>\n",
       "      <th>order_hour_of_day_22</th>\n",
       "      <th>order_hour_of_day_23</th>\n",
       "      <th>order_hour_of_day_3</th>\n",
       "      <th>order_hour_of_day_4</th>\n",
       "      <th>order_hour_of_day_5</th>\n",
       "      <th>order_hour_of_day_6</th>\n",
       "      <th>order_hour_of_day_7</th>\n",
       "      <th>order_hour_of_day_8</th>\n",
       "      <th>order_hour_of_day_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2539329</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_number  days_since_prior_order  aisle_id_1  aisle_id_10  \\\n",
       "order_id                                                                  \n",
       "2539329              1                       0           0            0   \n",
       "\n",
       "          aisle_id_100  aisle_id_101  aisle_id_102  aisle_id_103  \\\n",
       "order_id                                                           \n",
       "2539329              0             0             0             0   \n",
       "\n",
       "          aisle_id_104  aisle_id_105         ...           \\\n",
       "order_id                                     ...            \n",
       "2539329              0             0         ...            \n",
       "\n",
       "          order_hour_of_day_21  order_hour_of_day_22  order_hour_of_day_23  \\\n",
       "order_id                                                                     \n",
       "2539329                      0                     0                     0   \n",
       "\n",
       "          order_hour_of_day_3  order_hour_of_day_4  order_hour_of_day_5  \\\n",
       "order_id                                                                  \n",
       "2539329                     0                    0                    0   \n",
       "\n",
       "          order_hour_of_day_6  order_hour_of_day_7  order_hour_of_day_8  \\\n",
       "order_id                                                                  \n",
       "2539329                     0                    0                    1   \n",
       "\n",
       "          order_hour_of_day_9  \n",
       "order_id                       \n",
       "2539329                     0  \n",
       "\n",
       "[1 rows x 188 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_number</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>aisle_id_1</th>\n",
       "      <th>aisle_id_10</th>\n",
       "      <th>aisle_id_100</th>\n",
       "      <th>aisle_id_101</th>\n",
       "      <th>aisle_id_102</th>\n",
       "      <th>aisle_id_103</th>\n",
       "      <th>aisle_id_104</th>\n",
       "      <th>aisle_id_105</th>\n",
       "      <th>...</th>\n",
       "      <th>order_hour_of_day_21</th>\n",
       "      <th>order_hour_of_day_22</th>\n",
       "      <th>order_hour_of_day_23</th>\n",
       "      <th>order_hour_of_day_3</th>\n",
       "      <th>order_hour_of_day_4</th>\n",
       "      <th>order_hour_of_day_5</th>\n",
       "      <th>order_hour_of_day_6</th>\n",
       "      <th>order_hour_of_day_7</th>\n",
       "      <th>order_hour_of_day_8</th>\n",
       "      <th>order_hour_of_day_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2539329</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_number  days_since_prior_order  aisle_id_1  aisle_id_10  \\\n",
       "order_id                                                                  \n",
       "2539329              1                      -1          -1           -1   \n",
       "\n",
       "          aisle_id_100  aisle_id_101  aisle_id_102  aisle_id_103  \\\n",
       "order_id                                                           \n",
       "2539329             -1            -1            -1            -1   \n",
       "\n",
       "          aisle_id_104  aisle_id_105         ...           \\\n",
       "order_id                                     ...            \n",
       "2539329             -1            -1         ...            \n",
       "\n",
       "          order_hour_of_day_21  order_hour_of_day_22  order_hour_of_day_23  \\\n",
       "order_id                                                                     \n",
       "2539329                     -1                    -1                    -1   \n",
       "\n",
       "          order_hour_of_day_3  order_hour_of_day_4  order_hour_of_day_5  \\\n",
       "order_id                                                                  \n",
       "2539329                    -1                   -1                   -1   \n",
       "\n",
       "          order_hour_of_day_6  order_hour_of_day_7  order_hour_of_day_8  \\\n",
       "order_id                                                                  \n",
       "2539329                    -1                   -1                    1   \n",
       "\n",
       "          order_hour_of_day_9  \n",
       "order_id                       \n",
       "2539329                    -1  \n",
       "\n",
       "[1 rows x 188 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train[['order_dow', 'order_hour_of_day']] = X_train[['order_dow', 'order_hour_of_day']].astype(str)\n",
    "X_train = pd.get_dummies(X_train, columns=['order_dow', 'order_hour_of_day'])\n",
    "X_train = X_train.astype('int8')\n",
    "display(X_train.head(1))\n",
    "X_train = X_train.fillna(-1)\n",
    "display(X_train.head(1))\n",
    "X_train = X_train.replace(0,-1)\n",
    "display(X_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('None',)\n",
      "196 12427 26088\n",
      "('None',)\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "#vectorise the products list\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "value = pickle.load( open('/dict/prod_dict.p', 'rb'))\n",
    "dicts = []\n",
    "for i in value:\n",
    "    dicts.append(tuple(i.split()))\n",
    "print (dicts[49688])\n",
    "\n",
    "\n",
    "vectorizer = MultiLabelBinarizer(sparse_output=True).fit(dicts)\n",
    "\n",
    "#prod_dict = {value:key  for (value, key) in zip(value, key)}\n",
    "#print (list(vectorizer.classes_))\n",
    "#print (key[49688])\n",
    "#print (value[49688])\n",
    "#vectorizer = TfidfVectorizer(vocabulary = prod_dict)\n",
    "#vectorizer = CountVectorizer(vocabulary = prod_dict)\n",
    "train_target = df_train['products_list'].values\n",
    "\n",
    "print(train_target[1])\n",
    "y_train = []\n",
    "for i in train_target:\n",
    "    y_train.append(tuple(i.split()))\n",
    "print (y_train[0])\n",
    "    \n",
    "\n",
    "y_train = vectorizer.transform(y_train)\n",
    "print(y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "int8\n"
     ]
    }
   ],
   "source": [
    "#deleted df\n",
    "del df_train\n",
    "gc.collect()\n",
    "#custom round layer\n",
    "from keras.layers import Layer\n",
    "class Round(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Round, self).__init__(**kwargs)\n",
    "\n",
    "    def get_output(self, train=False):\n",
    "        X = self.get_input(train)\n",
    "        return K.round(X)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(Round, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "print (vectorizer.classes_[49688])\n",
    "y_train = y_train.astype('int8')\n",
    "print(y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.utils\n",
    "#y = y_train[:200000].todense()\n",
    "#y = to_categorical(y, num_classes=None)\n",
    "y_eval = y_train[199900:200000].todense()\n",
    "#y = y[:199900]\n",
    "#from scipy.sparse import csr_matrix\n",
    "#test = csr_matrix(y)\n",
    "#print(vectorizer.inverse_transform(test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(vectorizer.classes_), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3214874, 188)\n",
      "loaded on weights\n",
      "(100, 49689)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_number</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>aisle_id_1</th>\n",
       "      <th>aisle_id_10</th>\n",
       "      <th>aisle_id_100</th>\n",
       "      <th>aisle_id_101</th>\n",
       "      <th>aisle_id_102</th>\n",
       "      <th>aisle_id_103</th>\n",
       "      <th>aisle_id_104</th>\n",
       "      <th>aisle_id_105</th>\n",
       "      <th>...</th>\n",
       "      <th>order_hour_of_day_21</th>\n",
       "      <th>order_hour_of_day_22</th>\n",
       "      <th>order_hour_of_day_23</th>\n",
       "      <th>order_hour_of_day_3</th>\n",
       "      <th>order_hour_of_day_4</th>\n",
       "      <th>order_hour_of_day_5</th>\n",
       "      <th>order_hour_of_day_6</th>\n",
       "      <th>order_hour_of_day_7</th>\n",
       "      <th>order_hour_of_day_8</th>\n",
       "      <th>order_hour_of_day_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2539329</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_number  days_since_prior_order  aisle_id_1  aisle_id_10  \\\n",
       "order_id                                                                  \n",
       "2539329              1                      -1          -1           -1   \n",
       "\n",
       "          aisle_id_100  aisle_id_101  aisle_id_102  aisle_id_103  \\\n",
       "order_id                                                           \n",
       "2539329             -1            -1            -1            -1   \n",
       "\n",
       "          aisle_id_104  aisle_id_105         ...           \\\n",
       "order_id                                     ...            \n",
       "2539329             -1            -1         ...            \n",
       "\n",
       "          order_hour_of_day_21  order_hour_of_day_22  order_hour_of_day_23  \\\n",
       "order_id                                                                     \n",
       "2539329                     -1                    -1                    -1   \n",
       "\n",
       "          order_hour_of_day_3  order_hour_of_day_4  order_hour_of_day_5  \\\n",
       "order_id                                                                  \n",
       "2539329                    -1                   -1                   -1   \n",
       "\n",
       "          order_hour_of_day_6  order_hour_of_day_7  order_hour_of_day_8  \\\n",
       "order_id                                                                  \n",
       "2539329                    -1                   -1                    1   \n",
       "\n",
       "          order_hour_of_day_9  \n",
       "order_id                       \n",
       "2539329                    -1  \n",
       "\n",
       "[1 rows x 188 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(212,input_dim=188, activation='relu'))\n",
    "# Hidden layers\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(316,activation='relu'))\n",
    "model.add(Dense(486,activation='relu'))\n",
    "model.add(Dense(624,activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(700,activation='relu'))\n",
    "model.add(Dense(900,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "#output layer\n",
    "model.add(Dense(49689, activation='sigmoid'))\n",
    "\n",
    "#adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.99, epsilon=1e-03, decay=0.0001)\n",
    "RMSprop = keras.optimizers.RMSprop(lr=0.0001)\n",
    "#Nadam = keras.optimizers.Nadam(lr=0.001)\n",
    "#Adagrad = keras.optimizers.Adagrad(lr=0.001)\n",
    "try:\n",
    "    #load weights\n",
    "    model.load_weights(\"weights.best.hdf5\")\n",
    "    print('loaded on weights')\n",
    "except:\n",
    "    print('load weights failed')\n",
    "    model = load_model('my_model.hdf5')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer= RMSprop, metrics = ['accuracy'])\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "keras_train = np.array(X_train)\n",
    "keras_eval = np.array(X_train[199900:200000])\n",
    "\n",
    "print (y_eval.shape)\n",
    "display(X_train.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    number_of_batches = X.shape[0]/batch_size\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(np.shape(X)[0])\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    X =  X[shuffle_index]\n",
    "    y =  y[shuffle_index, :]\n",
    "    while 1:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[index_batch]\n",
    "        y_batch = y[index_batch,:].todense()\n",
    "        counter += 1\n",
    "        yield(X_batch,np.array(y_batch))\n",
    "        if (counter < number_of_batches):\n",
    "            np.random.shuffle(shuffle_index)\n",
    "            counter=0\n",
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "tot items to train: 2000\n",
      "starting epoch 0\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[999,49689]\n\t [[Node: logistic_loss_14/zeros_like = ZerosLike[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Log_18)]]\n\t [[Node: Mean_82/_1981 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_32_Mean_82\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'logistic_loss_14/zeros_like', defined at:\n  File \"/usr/local/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-104-9ffcff82bec6>\", line 33, in <module>\n    model.compile(loss='binary_crossentropy',optimizer= RMSprop, metrics = ['accuracy','MSLE'])\n  File \"/usr/local/lib/python3.5/site-packages/keras/models.py\", line 777, in compile\n    **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/keras/engine/training.py\", line 910, in compile\n    sample_weight, mask)\n  File \"/usr/local/lib/python3.5/site-packages/keras/engine/training.py\", line 436, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"/usr/local/lib/python3.5/site-packages/keras/losses.py\", line 51, in binary_crossentropy\n    return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1)\n  File \"/usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2771, in binary_crossentropy\n    logits=output)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py\", line 167, in sigmoid_cross_entropy_with_logits\n    zeros = array_ops.zeros_like(logits, dtype=logits.dtype)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1397, in zeros_like\n    return gen_array_ops._zeros_like(tensor, name=name)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3908, in _zeros_like\n    result = _op_def_lib.apply_op(\"ZerosLike\", x=x, name=name)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[999,49689]\n\t [[Node: logistic_loss_14/zeros_like = ZerosLike[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Log_18)]]\n\t [[Node: Mean_82/_1981 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_32_Mean_82\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[999,49689]\n\t [[Node: logistic_loss_14/zeros_like = ZerosLike[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Log_18)]]\n\t [[Node: Mean_82/_1981 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_32_Mean_82\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-aaa82545a748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_features_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtot_training\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtot_training\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'false'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#pred_class(y_eval,keras_eval)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[999,49689]\n\t [[Node: logistic_loss_14/zeros_like = ZerosLike[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Log_18)]]\n\t [[Node: Mean_82/_1981 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_32_Mean_82\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'logistic_loss_14/zeros_like', defined at:\n  File \"/usr/local/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-104-9ffcff82bec6>\", line 33, in <module>\n    model.compile(loss='binary_crossentropy',optimizer= RMSprop, metrics = ['accuracy','MSLE'])\n  File \"/usr/local/lib/python3.5/site-packages/keras/models.py\", line 777, in compile\n    **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/keras/engine/training.py\", line 910, in compile\n    sample_weight, mask)\n  File \"/usr/local/lib/python3.5/site-packages/keras/engine/training.py\", line 436, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"/usr/local/lib/python3.5/site-packages/keras/losses.py\", line 51, in binary_crossentropy\n    return K.mean(K.binary_crossentropy(y_pred, y_true), axis=-1)\n  File \"/usr/local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 2771, in binary_crossentropy\n    logits=output)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py\", line 167, in sigmoid_cross_entropy_with_logits\n    zeros = array_ops.zeros_like(logits, dtype=logits.dtype)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 1397, in zeros_like\n    return gen_array_ops._zeros_like(tensor, name=name)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3908, in _zeros_like\n    result = _op_def_lib.apply_op(\"ZerosLike\", x=x, name=name)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[999,49689]\n\t [[Node: logistic_loss_14/zeros_like = ZerosLike[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Log_18)]]\n\t [[Node: Mean_82/_1981 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_32_Mean_82\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "print('Training')\n",
    "\n",
    "batch_size = 1000\n",
    "epochs = 5\n",
    "n_batches = 2\n",
    "\n",
    "tot_training = min(batch_size*n_batches,keras_train.shape[0])\n",
    "print('tot items to train: {}'.format(tot_training))\n",
    "# Fit the model\n",
    "\n",
    "#hist = model.fit_generator(generator=batch_generator(keras_train, y_train, 1000),\n",
    "#                    nb_epoch=1, \n",
    "#                    samples_per_epoch=1000,verbose=2,validation_data = ( keras_eval, y_eval ))\n",
    "\n",
    "    \n",
    "# Training cycle\n",
    "for epoch in range(epochs):\n",
    "    # Loop over all batches\n",
    "        print('starting epoch {}'.format(epoch))\n",
    "        for batch_features, batch_labels in batch_features_labels(keras_train[:tot_training], y_train[:tot_training],batch_size):\n",
    "            y = batch_labels.todense()\n",
    "            model.fit(batch_features, y,batch_size=990,epochs=1,verbose=0, validation_split=0.001,callbacks= callbacks_list, shuffle='false')\n",
    "        #pred_class(y_eval,keras_eval)\n",
    "\n",
    "            \n",
    "#model.fit(keras_train, y, epochs=10, batch_size=1000,verbose=2, validation_split = 0.01, class_weight=class_weight) \n",
    "\n",
    "#score = model.evaluate(keras_eval, y_eval)\n",
    "\n",
    "#print('\\nTest score:', score[0])\n",
    "#print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting\n",
      "0.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model.hdf5\")\n",
    "\n",
    "def pred_class(y_eval,keras_eval):\n",
    "        from scipy.sparse import csr_matrix\n",
    "        print('Predicting')\n",
    "        predicted_output = model.predict(keras_eval)\n",
    "        predicted_output[predicted_output>=0.5] = 1\n",
    "        predicted_output[predicted_output<0.5] = 0\n",
    "        pred = csr_matrix(predicted_output)\n",
    "        y_eval_pred = vectorizer.inverse_transform(pred)\n",
    "        print (multilabel_fscore(y_eval,y_eval_pred))\n",
    "\n",
    "#print('true eval set values {}'.format(y_eval[0]))\n",
    "#print('pred eval set values {}\\n'.format(y_eval_pred[0]))\n",
    "print (pred_class(y_eval,keras_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

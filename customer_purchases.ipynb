{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the needed libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "import pickle\n",
    "color = sns.color_palette()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #Supress unnecessary warnings for readability and cleaner presentation\n",
    "import pickle\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) #Limiting floats output to 3 decimal points\n",
    "import gc\n",
    "print (gc.isenabled())\n",
    "\n",
    "from subprocess import check_output\n",
    "#print(check_output(['dir', 'input/']).decode(\"utf8\")) #check the files available in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_fscore(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    ex1:\n",
    "    y_true = [1, 2, 3]\n",
    "    y_pred = [2, 3]\n",
    "    return: 0.8\n",
    "    \n",
    "    ex2:\n",
    "    y_true = [\"None\"]\n",
    "    y_pred = [2, \"None\"]\n",
    "    return: 0.666\n",
    "    \n",
    "    ex3:\n",
    "    y_true = [4, 5, 6, 7]\n",
    "    y_pred = [2, 4, 8, 9]\n",
    "    return: 0.25\n",
    "    \n",
    "    \"\"\"\n",
    "    y_true, y_pred = set(y_true), set(y_pred)\n",
    "    \n",
    "    correct = sum([1 for i in y_pred if i in y_true])\n",
    "    \n",
    "    if correct > 0:\n",
    "        \n",
    "        precision = correct / len(y_pred)\n",
    "\n",
    "        recall =    correct / len(y_true)\n",
    "        \n",
    "        F1_score = (2 * precision * recall) / (precision + recall)\n",
    "        \n",
    "    else:\n",
    "        F1_score = 0\n",
    "    \n",
    "    return F1_score\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print(multilabel_fscore([2,3], [2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's get and put the data in  pandas dataframe\n",
    "\n",
    "order_products_train = pd.read_csv('input/order_products__train.csv')\n",
    "order_products_prior = pd.read_csv('input/order_products__prior.csv')\n",
    "orders = pd.read_csv('input/orders.csv')\n",
    "products = pd.read_csv('input/products.csv')\n",
    "aisles = pd.read_csv('input/aisles.csv')\n",
    "departments = pd.read_csv('input/departments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_products = products.merge(aisles, on ='aisle_id', how='left')\n",
    "df_products = df_products.merge(departments, on ='department_id', how='left')\n",
    "df_products.drop(['aisle_id','department_id'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_prior = order_products_prior.merge(df_products, on='product_id', how='left')\n",
    "df_prior.drop(['product_id'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = order_products_train.merge(df_products, on='product_id', how='left')\n",
    "df_train.drop(['product_id'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_orders = orders.merge(df_prior, on='order_id', how='left')\n",
    "df_orders = df_orders.merge(df_train, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train,df_prior,df_products,order_products_train,order_products_prior,orders,products,aisles,departments\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The order_products_train size is : \", order_products_train.shape)\n",
    "print(\"The order_products_prior size is : \", order_products_prior.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the number of the last order placed\n",
    "#split orders\n",
    "test_orders  = df_orders[df_orders['eval_set'] == 'test' ]\n",
    "prior_orders = df_orders[df_orders['eval_set'] == 'prior']\n",
    "train_orders = df_orders[df_orders['eval_set'] == 'train']\n",
    "prior_orders['num_orders'] = prior_orders.groupby(['user_id'])['order_number'].transform(max)\n",
    "train_orders['num_orders'] = train_orders.groupby(['user_id'])['order_number'].transform(max)\n",
    "test_orders['num_orders'] = test_orders.groupby(['user_id'])['order_number'].transform(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df_orders\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "pickle.dump(test_orders, open('test_orders.p', 'wb'), protocol=4)\n",
    "\n",
    "pickle.dump(prior_orders, open('prior_orders.p', 'wb'), protocol=4)\n",
    "\n",
    "pickle.dump(train_orders, open('train_orders.p', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint\n",
    "data can be loaded from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_orders = pickle.load(open('test_orders.p', mode='rb'))\n",
    "#prior_orders = pickle.load(open('prior_orders.p', mode='rb'))\n",
    "train_orders = pickle.load(open('train_orders.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_orders.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate all product-ids into a single string\n",
    "# thanks to https://www.kaggle.com/eoakley/start-here-simple-submission\n",
    "\n",
    "def products_concat(series):\n",
    "    out = ''\n",
    "    for product in series:\n",
    "        if product > 0:\n",
    "            out = out + str(int(product)) + ' '\n",
    "    \n",
    "    if out != '':\n",
    "        return out.rstrip()\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique orders and unique products\n",
    "orders_Unique = len(set(order_products_all.order_id))\n",
    "products_Unique = len(set(order_products_all.product_id))\n",
    "print(\"There are %s orders for %s products\" %(orders_Unique, products_Unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = order_products_all.groupby(\"order_id\")[\"add_to_cart_order\"].aggregate(\"max\").reset_index()\n",
    "grouped = grouped.add_to_cart_order.value_counts()\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "plt.xticks(rotation='vertical')\n",
    "sns.barplot(grouped.index, grouped.values)\n",
    "\n",
    "plt.ylabel('Number of Orders', fontsize=13)\n",
    "plt.xlabel('Number of products added in order', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = order_products_all.groupby(\"product_id\")[\"reordered\"].aggregate({'Total_reorders': 'count'}).reset_index()\n",
    "grouped = pd.merge(grouped, products[['product_id', 'product_name']], how='left', on=['product_id'])\n",
    "grouped = grouped.sort_values(by='Total_reorders', ascending=False)[:10]\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped  = grouped.groupby(['product_name']).sum()['Total_reorders'].sort_values(ascending=False)\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "plt.xticks(rotation='vertical')\n",
    "sns.barplot(grouped.index, grouped.values)\n",
    "plt.ylabel('Number of Reorders', fontsize=13)\n",
    "plt.xlabel('Most ordered Products', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = order_products_all.groupby(\"product_id\")[\"reordered\"].aggregate({'reorder_sum': sum,'reorder_total': 'count'}).reset_index()\n",
    "grouped['reorder_probability'] = grouped['reorder_sum'] / grouped['reorder_total']\n",
    "grouped = pd.merge(grouped, products[['product_id', 'product_name']], how='left', on=['product_id'])\n",
    "grouped = grouped[grouped.reorder_total > 75].sort_values(['reorder_probability'], ascending=False)[:10]\n",
    "grouped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
